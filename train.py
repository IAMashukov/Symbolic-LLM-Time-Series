import ast 
import logging 
import os 
import re
import sys 
import json 
import itertools 
import random 
from copy import deepcopy 
from pathlib import Path 
from functools import partial 
from typing import List, Iterator, Optional, Dict 
import argparse 
import numpy as np 
import torch 
import torch.distributed as dist 
from torch.utils.data import IterableDataset, get_worker_info 
import transformers 
from transformers import ( 
    AutoModelForSeq2SeqLM,
    AutoModelForCausalLM,
    AutoConfig, 
    T5Config, 
    Trainer, 
    TrainingArguments,
)
import accelerate 
import gluonts 
from gluonts.dataset.common import FileDataset 
# lets you load a time series dataset from a directory of JSON files, 
# which follow GluonTS's required format for training and evaluation.
from gluonts.itertools import Cyclic, Map, Filter 

from gluonts.transform import (
    FilterTransformation,
    TestSplitSampler,
    ValidationSplitSampler,
    InstanceSplitter,
    ExpectedNumInstanceSampler,
    MissingValueImputation,
    LeavesMissingValues,
    LastValueImputation,
)

'''
What Each Component Does:
Module - Description

FilterTransformation - Filters time series based on a custom
condition (e.g. only keep long enough series).

TestSplitSampler - Defines how to sample data for the test set
(e.g. single or multiple windows from the end)

ValidationSplitSampler - Like TestSplitSampler, 
but for validation (typically earlier in the series)

InstanceSplitter - Splits a time series into training/forecast
instances with sliding or rolling windows.

ExpectedNumInstanceSampler - Chooses split points based on how many
instances you want to extract.

MissingValueImputation - Abstract base class for filling in 
missing values.

LeavesMissingValues - No imputation â€” leaves missing values as-is.

LastValueImputation - Fills missing values using the last
observed value (useful for sensors, etc.).
'''



def main():

    return 



if __name__=="__main__":
    main()